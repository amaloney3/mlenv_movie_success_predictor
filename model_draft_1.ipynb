{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sklearn as skl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             budget             id    popularity       revenue       runtime  \\\n",
      "count  1.290600e+04   12906.000000  12906.000000  1.290600e+04  12902.000000   \n",
      "mean   1.254855e+07  107530.588951      5.411736  3.309889e+07     96.528058   \n",
      "std    3.020407e+07  123459.390616      9.775813  1.138658e+08     31.869326   \n",
      "min    0.000000e+00       5.000000      0.000000  0.000000e+00      0.000000   \n",
      "25%    0.000000e+00   14913.250000      1.013951  0.000000e+00     87.000000   \n",
      "50%    0.000000e+00   45188.500000      3.372783  0.000000e+00     95.000000   \n",
      "75%    1.000000e+07  173995.000000      7.888230  5.376946e+06    105.000000   \n",
      "max    3.800000e+08  464819.000000    547.488298  2.787965e+09    877.000000   \n",
      "\n",
      "       vote_average    vote_count  release_year  \n",
      "count  12906.000000  12906.000000  12906.000000  \n",
      "mean       5.639648    291.211917   2006.070820  \n",
      "std        1.558221    850.228648      7.619696  \n",
      "min        0.000000      0.000000   1990.000000  \n",
      "25%        5.000000      8.000000   2000.000000  \n",
      "50%        5.900000     29.000000   2008.000000  \n",
      "75%        6.600000    155.000000   2013.000000  \n",
      "max       10.000000  14075.000000   2020.000000  \n",
      "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
      "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
      "       'popularity', 'poster_path', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
      "       'vote_average', 'vote_count', 'release_year', '1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read in the demonstration data and keep only a few variables\n",
    "input_df=pd.read_csv(\"Resources/segment1_input.csv\", low_memory=False)\n",
    "print(input_df.describe())\n",
    "print(input_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "belongs_to_collection     object\n",
       "homepage                  object\n",
       "runtime                  float64\n",
       "vote_average             float64\n",
       "release_year             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select columns to keep for model\n",
    "df=input_df[[\"belongs_to_collection\", \"homepage\", \"runtime\", \"vote_average\", \"release_year\"]]\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>homepage</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'id': 645, 'name': 'James Bond Collection', '...</td>\n",
       "      <td>http://www.mgm.com/view/movie/757/Goldeneye/</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'id': 117693, 'name': 'Balto Collection', 'po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'id': 3167, 'name': 'Ace Ventura Collection',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                belongs_to_collection  \\\n",
       "0   {'id': 10194, 'name': 'Toy Story Collection', ...   \n",
       "1                                                 NaN   \n",
       "2   {'id': 119050, 'name': 'Grumpy Old Men Collect...   \n",
       "3                                                 NaN   \n",
       "4   {'id': 96871, 'name': 'Father of the Bride Col...   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   {'id': 645, 'name': 'James Bond Collection', '...   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12  {'id': 117693, 'name': 'Balto Collection', 'po...   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18  {'id': 3167, 'name': 'Ace Ventura Collection',...   \n",
       "19                                                NaN   \n",
       "\n",
       "                                        homepage  runtime  vote_average  \\\n",
       "0           http://toystory.disney.com/toy-story     81.0           7.7   \n",
       "1                                            NaN    104.0           6.9   \n",
       "2                                            NaN    101.0           6.5   \n",
       "3                                            NaN    127.0           6.1   \n",
       "4                                            NaN    106.0           5.7   \n",
       "5                                            NaN    170.0           7.7   \n",
       "6                                            NaN    127.0           6.2   \n",
       "7                                            NaN     97.0           5.4   \n",
       "8                                            NaN    106.0           5.5   \n",
       "9   http://www.mgm.com/view/movie/757/Goldeneye/    130.0           6.6   \n",
       "10                                           NaN    106.0           6.5   \n",
       "11                                           NaN     88.0           5.7   \n",
       "12                                           NaN     78.0           7.1   \n",
       "13                                           NaN    192.0           7.1   \n",
       "14                                           NaN    119.0           5.7   \n",
       "15                                           NaN    178.0           7.8   \n",
       "16                                           NaN    136.0           7.2   \n",
       "17                                           NaN     98.0           6.5   \n",
       "18                                           NaN     90.0           6.1   \n",
       "19                                           NaN    103.0           5.4   \n",
       "\n",
       "    release_year  \n",
       "0         1995.0  \n",
       "1         1995.0  \n",
       "2         1995.0  \n",
       "3         1995.0  \n",
       "4         1995.0  \n",
       "5         1995.0  \n",
       "6         1995.0  \n",
       "7         1995.0  \n",
       "8         1995.0  \n",
       "9         1995.0  \n",
       "10        1995.0  \n",
       "11        1995.0  \n",
       "12        1995.0  \n",
       "13        1995.0  \n",
       "14        1995.0  \n",
       "15        1995.0  \n",
       "16        1995.0  \n",
       "17        1995.0  \n",
       "18        1995.0  \n",
       "19        1995.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "no     11109\n",
      "yes     1797\n",
      "Name: collection, dtype: int64\n",
      "3928\n",
      "no     8978\n",
      "yes    3928\n",
      "Name: website, dtype: int64\n",
      "yes    9563\n",
      "no     3343\n",
      "Name: success, dtype: int64\n",
      "Index(['runtime', 'release_year', 'collection', 'website', 'success'], dtype='object')\n",
      "runtime         float64\n",
      "release_year    float64\n",
      "collection       object\n",
      "website          object\n",
      "success          object\n",
      "dtype: object\n",
      "   runtime  release_year collection website success\n",
      "0     81.0        1995.0        yes     yes     yes\n",
      "1    104.0        1995.0         no      no     yes\n",
      "2    101.0        1995.0        yes      no     yes\n",
      "3    127.0        1995.0         no      no     yes\n",
      "4    106.0        1995.0        yes      no     yes\n"
     ]
    }
   ],
   "source": [
    "# convert belongs_to_collection, homepage and success to binary(0,1)\n",
    "print(df[\"belongs_to_collection\"].notnull().sum())\n",
    "collection=df[\"belongs_to_collection\"].notnull().replace([True, False], [\"yes\", \"no\"])\n",
    "collection.name=\"collection\"\n",
    "print(collection.value_counts())\n",
    "print(df[\"homepage\"].notnull().sum())\n",
    "website=df[\"homepage\"].notnull().replace([True, False], [\"yes\", \"no\"])\n",
    "website.name=\"website\"\n",
    "print(website.value_counts())\n",
    "success=df[\"vote_average\"].apply(lambda z: \"yes\" if z > 5 else \"no\")\n",
    "success.name=\"success\"\n",
    "print(success.value_counts())\n",
    "clean_df = pd.concat([df, collection, website, success], axis=1, ignore_index=False, join=\"inner\")\n",
    "clean_df.drop([\"belongs_to_collection\", \"homepage\", \"vote_average\"], axis=1, inplace=True)\n",
    "print(clean_df.columns)\n",
    "print(clean_df.dtypes)\n",
    "print(clean_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['collection', 'website', 'success']\n"
     ]
    }
   ],
   "source": [
    "clean_cat=clean_df.dtypes[clean_df.dtypes == \"object\"].index.tolist()\n",
    "print(clean_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_no</th>\n",
       "      <th>collection_yes</th>\n",
       "      <th>website_no</th>\n",
       "      <th>website_yes</th>\n",
       "      <th>success_no</th>\n",
       "      <th>success_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_no  collection_yes  website_no  website_yes  success_no  \\\n",
       "0            0.0             1.0         0.0          1.0         0.0   \n",
       "1            1.0             0.0         1.0          0.0         0.0   \n",
       "2            0.0             1.0         1.0          0.0         0.0   \n",
       "3            1.0             0.0         1.0          0.0         0.0   \n",
       "4            0.0             1.0         1.0          0.0         0.0   \n",
       "\n",
       "   success_yes  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Create a OneHotEncoder instance\n",
    "enc =OneHotEncoder(sparse=False)\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df =pd.DataFrame(enc.fit_transform(clean_df[clean_cat]))\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns =enc.get_feature_names(clean_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   runtime  release_year collection website success  collection_no  \\\n",
      "0     81.0        1995.0        yes     yes     yes            0.0   \n",
      "1    104.0        1995.0         no      no     yes            1.0   \n",
      "2    101.0        1995.0        yes      no     yes            0.0   \n",
      "3    127.0        1995.0         no      no     yes            1.0   \n",
      "4    106.0        1995.0        yes      no     yes            0.0   \n",
      "\n",
      "   collection_yes  website_no  website_yes  success_no  success_yes  \n",
      "0             1.0         0.0          1.0         0.0          1.0  \n",
      "1             0.0         1.0          0.0         0.0          1.0  \n",
      "2             1.0         1.0          0.0         0.0          1.0  \n",
      "3             0.0         1.0          0.0         0.0          1.0  \n",
      "4             1.0         1.0          0.0         0.0          1.0  \n",
      "   runtime  release_year  collection_no  collection_yes  website_no  \\\n",
      "0     81.0        1995.0            0.0             1.0         0.0   \n",
      "1    104.0        1995.0            1.0             0.0         1.0   \n",
      "2    101.0        1995.0            0.0             1.0         1.0   \n",
      "3    127.0        1995.0            1.0             0.0         1.0   \n",
      "4    106.0        1995.0            0.0             1.0         1.0   \n",
      "\n",
      "   website_yes  success_no  success_yes  \n",
      "0          1.0         0.0          1.0  \n",
      "1          0.0         0.0          1.0  \n",
      "2          0.0         0.0          1.0  \n",
      "3          0.0         0.0          1.0  \n",
      "4          0.0         0.0          1.0  \n"
     ]
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "clean_df =clean_df.merge(encode_df,left_index=True,right_index=True)\n",
    "print(clean_df.head())\n",
    "clean_df=clean_df.drop(clean_cat,axis=1, inplace=True)\n",
    "print(clean_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "y =clean_df[\"success_yes\"].values\n",
    "X =clean_df.drop([\"success_yes\",\"success_no\"],1).values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[6.700e+01 1.993e+03 0.000e+00 1.000e+00 1.000e+00 0.000e+00]\n",
      " [9.900e+01 1.993e+03 1.000e+00 0.000e+00 1.000e+00 0.000e+00]\n",
      " [9.200e+01 2.007e+03 1.000e+00 0.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.160e+02 2.011e+03 1.000e+00 0.000e+00 1.000e+00 0.000e+00]\n",
      " [9.400e+01 1.996e+03 1.000e+00 0.000e+00 1.000e+00 0.000e+00]\n",
      " [9.800e+01 2.012e+03 1.000e+00 0.000e+00 1.000e+00 0.000e+00]]\n",
      "[0. 1. 1. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.93445643 -1.7125053  -2.49354125  2.49354125  0.65985946 -0.65985946]\n",
      " [ 0.07832548 -1.7125053   0.40103608 -0.40103608  0.65985946 -0.65985946]\n",
      " [-0.14322056  0.12191955  0.40103608 -0.40103608  0.65985946 -0.65985946]\n",
      " ...\n",
      " [ 0.61636587  0.64604093  0.40103608 -0.40103608  0.65985946 -0.65985946]\n",
      " [-0.07992169 -1.31941426  0.40103608 -0.40103608  0.65985946 -0.65985946]\n",
      " [ 0.04667605  0.77707128  0.40103608 -0.40103608  0.65985946 -0.65985946]]\n",
      "[[ 0.10997492  0.25294989  0.40103608 -0.40103608 -1.51547422  1.51547422]\n",
      " [-0.11157113  1.43222301  0.40103608 -0.40103608  0.65985946 -0.65985946]\n",
      " [ 0.67966474 -0.14014115  0.40103608 -0.40103608  0.65985946 -0.65985946]\n",
      " ...\n",
      " [-1.78899116 -1.18838391  0.40103608 -0.40103608  0.65985946 -0.65985946]\n",
      " [-0.11157113  1.30119266  0.40103608 -0.40103608 -1.51547422  1.51547422]\n",
      " [-0.14322056  1.03913197  0.40103608 -0.40103608  0.65985946 -0.65985946]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create scaler instance\n",
    "X_scaler =skl.preprocessing.StandardScaler()\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "# Scale the data\n",
    "X_train_scaled =X_scaler.transform(X_train)\n",
    "X_test_scaled =X_scaler.transform(X_test)\n",
    "print(X_train_scaled)\n",
    "print(X_test_scaled)\n",
    "print(type(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model\n",
    "number_input_features =len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 10 \n",
    "nn =tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our first Dense layer, including the input layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,activation=\"relu\",input_dim=number_input_features))\n",
    "# Add the output layer that uses a probability activation function\n",
    "nn.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the Sequential model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "303/303 [==============================] - 0s 386us/step - loss: nan - accuracy: 0.4372\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 0s 369us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 0s 379us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 0s 365us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 0s 369us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 0s 402us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 0s 375us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 0s 382us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 0s 369us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 0s 382us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 0s 379us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 0s 379us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 0s 375us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 0s 369us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 0s 408us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 0s 369us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 0s 379us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 0s 382us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 0s 379us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 0s 388us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 0s 385us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 0s 402us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 0s 379us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 0s 375us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 0s 402us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 0s 402us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 0s 375us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 0s 405us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 0s 395us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 0s 392us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 0s 382us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 0s 411us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 0s 398us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 0s 382us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 0s 382us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 0s 395us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 0s 392us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 0s 375us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 0s 379us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 0s 382us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 0s 379us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 0s 372us/step - loss: nan - accuracy: 0.2545\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "fit_model =nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 - 0s - loss: nan - accuracy: 0.2727\n",
      "Loss: nan, Accuracy: 0.2726990878582001\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss,model_accuracy =nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37nbext",
   "language": "python",
   "name": "py37nbext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
