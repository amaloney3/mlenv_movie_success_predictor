{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Model Segment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This version of the model looks at incorporating director data as a feature:\n",
    "\n",
    "### new features:\n",
    "* count of movies by director\n",
    "* success rate by director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR U\n"
     ]
    }
   ],
   "source": [
    "# Choose type of model to run:\n",
    "model_type = 'LR'  # LR = logistic regression, NN = neural net, SV = support vector machine\n",
    "# SVM is not running for some reason???? doesn't finish fit step?\n",
    "def select_model(mtype):\n",
    "    if mtype == 'LR':\n",
    "        return 'U'\n",
    "    elif mtype == 'NN':\n",
    "        return 'S'\n",
    "    elif mtype == 'SV':\n",
    "        return 'S'\n",
    "\n",
    "dataset = select_model(model_type)\n",
    "print(model_type, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['director_list', 'duration', 'g_Action_IM', 'g_Adult', 'g_Adventure_IM',\n",
      "       'g_Animation_IM', 'g_Biography', 'g_Comedy_IM', 'g_Crime_IM',\n",
      "       'g_Documentary_IM', 'g_Drama_IM', 'g_Family_IM', 'g_Fantasy_IM',\n",
      "       'g_History_IM', 'g_Horror_IM', 'g_Music_IM', 'g_Musical',\n",
      "       'g_Mystery_IM', 'g_Romance_IM', 'g_Thriller_IM', 'g_War_IM',\n",
      "       'g_Western_IM', 'release_year_IM', 'success'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# input merged dataset and select the appropriate dataframe\n",
    "df=pd.read_csv(\"Resources/merged_movies.csv\", low_memory=False)\n",
    "\n",
    "# drop genre variables from TMDB \n",
    "df.drop(['g_Action_TM', 'g_Adventure_TM', 'g_Animation_TM', 'g_Comedy_TM', 'g_Crime_TM', \n",
    "       'g_Documentary_TM', 'g_Drama_TM', 'g_Family_TM', 'g_Fantasy_TM', 'g_History_TM', 'g_Horror_TM',\n",
    "       'g_Music_TM', 'g_Mystery_TM', 'g_News', 'g_Reality_TV', 'g_Romance_TM',\n",
    "       'g_Sci_Fi', 'g_Sport', 'g_Thriller_TM','g_War_TM', 'g_Western_TM'], axis=1, inplace=True)\n",
    "\n",
    "# drop columns with high percentage of missing values, and not needed\n",
    "df.drop([\"budget_IM\", \"budget_TM\", \"collection\", \"g_Foreign\", \"genre_name\", \"metascore\", \"orig_lang_cd\", \n",
    "              \"original_language\", \"popularity\", \"release_year_TM\", \"revenue\", \"runtime\", \"usa_gross_income\", \n",
    "              \"website\", \"worlwide_gross_income\", \"year\"], axis=1, inplace=True)\n",
    "\n",
    "# drop columns with too many unique values \n",
    "df.drop([\"_merge\", \"country\", \"genre_list\", \"imdb_id\", \"language\", \"title\"], axis=1, inplace=True)\n",
    "\n",
    "# Drop any rows with missing values. Reassess whether the nulls can/should be recoded and kept.\n",
    "df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "# Choose dependent = predicted value:\n",
    "# Options: avg_vote, reviews_from_critics, reviews_from_users, votes\n",
    "# For this model pass, use avg_vote >= 7 as success\n",
    "df[\"success\"] = df[\"avg_vote\"].map(lambda x: 1 if x>= 7.0 else 0)\n",
    "\n",
    "# Drop unneeded dependent variables\n",
    "df.drop([\"avg_vote\", \"reviews_from_users\", \"reviews_from_critics\", \"votes\"], axis=1, inplace=True)\n",
    "\n",
    "# Categorical variables for encoding, if needed\n",
    "cat_vars = ['g_Action_IM', 'g_Adult', 'g_Adventure_IM',\n",
    "       'g_Animation_IM', 'g_Biography', 'g_Comedy_IM', 'g_Crime_IM',\n",
    "       'g_Documentary_IM', 'g_Drama_IM', 'g_Family_IM', 'g_Fantasy_IM',\n",
    "       'g_History_IM', 'g_Horror_IM', 'g_Music_IM', 'g_Musical',\n",
    "       'g_Mystery_IM', 'g_Romance_IM', 'g_Thriller_IM', 'g_War_IM',\n",
    "       'g_Western_IM']\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"max_rows\", 20)\n",
    "\n",
    "# extract info from director feature\n",
    "# there are 52,754 movies with 1 director, and 3,777 movies with 2 directors\n",
    "# there are 26,593 unique values of \"director\" (counting a pair of directors as a single value)\n",
    "\n",
    "# hypothesis: more movies associated with a director indicates the director is considered more worthy of investment, \n",
    "# so considered by investors to be more successful?\n",
    "# 58% of directors have 1 movie\n",
    "# 17% of directors have 2 movies\n",
    "#  7% of directors have 3 movies\n",
    "\n",
    "# hypothesis: can calculate success ratio for each director and use as a feature in the model     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " df columns Index(['director_list', 'duration', 'g_Action_IM', 'g_Adult', 'g_Adventure_IM',\n",
      "       'g_Animation_IM', 'g_Biography', 'g_Comedy_IM', 'g_Crime_IM',\n",
      "       'g_Documentary_IM', 'g_Drama_IM', 'g_Family_IM', 'g_Fantasy_IM',\n",
      "       'g_History_IM', 'g_Horror_IM', 'g_Music_IM', 'g_Musical',\n",
      "       'g_Mystery_IM', 'g_Romance_IM', 'g_Thriller_IM', 'g_War_IM',\n",
      "       'g_Western_IM', 'release_year_IM', 'success'],\n",
      "      dtype='object')\n",
      "\n",
      " directors cols Int64Index([0, 1], dtype='int64')\n",
      "\n",
      " length 56531\n",
      "\n",
      " length: 56531\n",
      "\n",
      " length df  56531\n",
      "\n",
      " df columns  Index(['duration', 'g_Action_IM', 'g_Adult', 'g_Adventure_IM',\n",
      "       'g_Animation_IM', 'g_Biography', 'g_Comedy_IM', 'g_Crime_IM',\n",
      "       'g_Documentary_IM', 'g_Drama_IM', 'g_Family_IM', 'g_Fantasy_IM',\n",
      "       'g_History_IM', 'g_Horror_IM', 'g_Music_IM', 'g_Musical',\n",
      "       'g_Mystery_IM', 'g_Romance_IM', 'g_Thriller_IM', 'g_War_IM',\n",
      "       'g_Western_IM', 'release_year_IM', 'success', 'Director_1',\n",
      "       'Director_2'],\n",
      "      dtype='object')\n",
      "\n",
      " df:     duration  g_Action_IM  g_Adult  g_Adventure_IM  g_Animation_IM  \\\n",
      "0     106.0          0.0      0.0             0.0             0.0   \n",
      "1      90.0          0.0      0.0             0.0             0.0   \n",
      "2      45.0          0.0      0.0             0.0             0.0   \n",
      "3     160.0          0.0      0.0             0.0             0.0   \n",
      "4      76.0          0.0      0.0             0.0             0.0   \n",
      "\n",
      "   g_Biography  g_Comedy_IM  g_Crime_IM  g_Documentary_IM  g_Drama_IM  ...  \\\n",
      "0          0.0          0.0         0.0               0.0         1.0  ...   \n",
      "1          0.0          0.0         0.0               0.0         1.0  ...   \n",
      "2          0.0          0.0         0.0               0.0         1.0  ...   \n",
      "3          1.0          0.0         0.0               0.0         1.0  ...   \n",
      "4          0.0          1.0         0.0               0.0         1.0  ...   \n",
      "\n",
      "   g_Musical  g_Mystery_IM  g_Romance_IM  g_Thriller_IM  g_War_IM  \\\n",
      "0        0.0           0.0           1.0            0.0       0.0   \n",
      "1        0.0           0.0           0.0            0.0       0.0   \n",
      "2        0.0           0.0           1.0            0.0       0.0   \n",
      "3        0.0           0.0           0.0            0.0       0.0   \n",
      "4        0.0           0.0           0.0            0.0       0.0   \n",
      "\n",
      "   g_Western_IM  release_year_IM  success        Director_1      Director_2  \n",
      "0           0.0           2005.0        0  Raymond Longford             NaN  \n",
      "1           0.0           2016.0        0    Arthur Robison             NaN  \n",
      "2           0.0           1983.0        1      Jean Epstein             NaN  \n",
      "3           0.0           2004.0        1  Cecil B. DeMille             NaN  \n",
      "4           0.0           1970.0        1   Edward Sedgwick   Buster Keaton  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract director names from director_list and put in two columns\n",
    "\n",
    "# Issue = names with a single quote are inside double quotes\n",
    "# in merged file looks like: Joe D'Amato\"\"]\"\n",
    "# see how this is handled in database\n",
    "# may need to modify the search based on the contents of the database\n",
    "\n",
    "# There's probably a better way of dealing with lists in a df column, this is a rather slow\n",
    "\n",
    "directors = df[\"director_list\"].copy() # series of directors in a string, index=original\n",
    "directors_list = directors.apply(eval) # convert series of strings to series of lists of directors, index=original\n",
    "directors_cols = pd.DataFrame(index=df.index.copy())  # initialize df to hold directors names, index=original\n",
    "\n",
    "# Create dataframe with director name as index, count of movies, count of successes, win_rate\n",
    "\n",
    "# Output list of directors into 2 columns\n",
    "# there must be a better way than this:\n",
    "\n",
    "# To iterate over items in a pandas Series use series.iterrows() function which returns an iterator, a tuple\n",
    "# yielding index and value for each item\n",
    "# Series.iteritems(self)\n",
    "# index – index of the series\n",
    "# value – value is the contents of the series item\n",
    "# it – it is the generator that iterates over the rows of DataFrame.\n",
    "\n",
    "# index is class int\n",
    "# value is class list\n",
    "# value contains up to 2 directors\n",
    "      \n",
    "for index, row  in directors_list.iteritems():\n",
    "    n = len(row)\n",
    "    if n == 1:\n",
    "        directors_cols.loc[index, 0] = row[0]\n",
    "    else:\n",
    "        directors_cols.loc[index, 0] = row[0]\n",
    "        directors_cols.loc[index, 1] = row[1]\n",
    "        \n",
    "# Update df with directors in two columns. Drop the original string column\n",
    "print(f'\\n df columns {df.columns}')\n",
    "print(f'\\n directors cols {directors_cols.columns}')\n",
    "print(f'\\n length {len(df)}')\n",
    "directors_cols.rename(columns={0:'Director_1', 1:'Director_2'}, inplace=True)\n",
    "print(f'\\n length: {len(directors_cols)}')\n",
    "\n",
    "df = pd.concat([df, directors_cols], axis=1, ignore_index=False, join=\"inner\")\n",
    "df.drop([\"director_list\"], axis=1, inplace=True) \n",
    "print(f'\\n length df  {len(df)}')\n",
    "print(f'\\n df columns  {df.columns}')\n",
    "print(f'\\n df:  {df.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Director_1', 'Director_2', 'success'], dtype='object')\n",
      "\n",
      " directors1: count unique: 25254, index: Index([''Evil' Ted Smith', ''Philthy' Phil Phillips', 'A. Dean Bell',\n",
      "       'A. Hans Scheirl', 'A. Jagadesh', 'A. Karunakaran', 'A. Mahadev',\n",
      "       'A. Muthu', 'A. Rajdeep', 'A. Razak Mohaideen',\n",
      "       ...\n",
      "       'Özcan Deniz', 'Özer Kiziltan', 'Özgür Bakar', 'Özgür Sevimli',\n",
      "       'Özgür Yildirim', 'Özhan Eren', 'Øystein Karlsen', 'Øystein Stene',\n",
      "       'Ümit Cin Güven', 'Ümit Ünal'],\n",
      "      dtype='object', name='Director_1', length=25254), head:                          count  sum\n",
      "Director_1                         \n",
      "'Evil' Ted Smith             1    0\n",
      "'Philthy' Phil Phillips      1    0\n",
      "A. Dean Bell                 2    0\n",
      "A. Hans Scheirl              1    0\n",
      "A. Jagadesh                  1    0\n",
      "\n",
      " directors2: count_unique: 2962, index: Index([' A. Blaine Miller', ' A.L. Vijay', ' A.S. Ravindra Babu', ' Aaron Lim',\n",
      "       ' Aaron Moorhead', ' Aaron Nee', ' Aaron Osborne', ' Aaron Russo',\n",
      "       ' Aaron Seltzer', ' Aaron T. Wells',\n",
      "       ...\n",
      "       ' Édouard Molinaro', ' Éric S. Boisvert', ' Éric Toledano',\n",
      "       ' Éric Warin', ' Éric du Potet', ' Éva Gárdos', ' Ícaro Martins',\n",
      "       ' Ömer Faruk Sorak', ' Özgür Bakar', ' Ülo Pikkov'],\n",
      "      dtype='object', name='Director_2', length=2962), head:                      count  sum\n",
      "Director_2                     \n",
      " A. Blaine Miller        1    0\n",
      " A.L. Vijay              7    2\n",
      " A.S. Ravindra Babu      1    0\n",
      " Aaron Lim               1    0\n",
      " Aaron Moorhead          4    0\n",
      "Index([''Evil' Ted Smith', ''Philthy' Phil Phillips', 'A. Dean Bell',\n",
      "       'A. Hans Scheirl', 'A. Jagadesh', 'A. Karunakaran', 'A. Mahadev',\n",
      "       'A. Muthu', 'A. Rajdeep', 'A. Razak Mohaideen',\n",
      "       ...\n",
      "       'Özcan Deniz', 'Özer Kiziltan', 'Özgür Bakar', 'Özgür Sevimli',\n",
      "       'Özgür Yildirim', 'Özhan Eren', 'Øystein Karlsen', 'Øystein Stene',\n",
      "       'Ümit Cin Güven', 'Ümit Ünal'],\n",
      "      dtype='object', name='Director_1', length=25254) Index([' A. Blaine Miller', ' A.L. Vijay', ' A.S. Ravindra Babu', ' Aaron Lim',\n",
      "       ' Aaron Moorhead', ' Aaron Nee', ' Aaron Osborne', ' Aaron Russo',\n",
      "       ' Aaron Seltzer', ' Aaron T. Wells',\n",
      "       ...\n",
      "       ' Édouard Molinaro', ' Éric S. Boisvert', ' Éric Toledano',\n",
      "       ' Éric Warin', ' Éric du Potet', ' Éva Gárdos', ' Ícaro Martins',\n",
      "       ' Ömer Faruk Sorak', ' Özgür Bakar', ' Ülo Pikkov'],\n",
      "      dtype='object', name='Director_2', length=2962)\n",
      "\n",
      " Index([' A. Blaine Miller', ' A.L. Vijay', ' A.S. Ravindra Babu', ' Aaron Lim',\n",
      "       ' Aaron Moorhead', ' Aaron Nee', ' Aaron Osborne', ' Aaron Russo',\n",
      "       ' Aaron Seltzer', ' Aaron T. Wells',\n",
      "       ...\n",
      "       'Özcan Deniz', 'Özer Kiziltan', 'Özgür Bakar', 'Özgür Sevimli',\n",
      "       'Özgür Yildirim', 'Özhan Eren', 'Øystein Karlsen', 'Øystein Stene',\n",
      "       'Ümit Cin Güven', 'Ümit Ünal'],\n",
      "      dtype='object', name='Director', length=28216)\n",
      "\n",
      "                      movie_cnt  success_cnt  win_rate\n",
      "Director                                             \n",
      " A. Blaine Miller          1.0          0.0  0.000000\n",
      " A.L. Vijay                7.0          2.0  0.285714\n",
      " A.S. Ravindra Babu        1.0          0.0  0.000000\n",
      " Aaron Lim                 1.0          0.0  0.000000\n",
      " Aaron Moorhead            4.0          0.0  0.000000\n",
      "\n",
      " 28216\n"
     ]
    }
   ],
   "source": [
    "# Calculate movies and success_rate by director\n",
    "# attach success indicator to directors_cols, by original index\n",
    "success = df[\"success\"].copy()         # series of success indicators, index=original\n",
    "director_success = pd.concat([directors_cols, success], axis=1, ignore_index=False, join=\"inner\")\n",
    "print(director_success.columns)\n",
    "directors1 = director_success[[\"Director_1\", \"success\"]].copy()\n",
    "directors2 = director_success[[\"Director_2\", \"success\"]].copy()\n",
    "directors2.dropna(inplace=True)\n",
    "\n",
    "# get counts by director for both directors \n",
    "d1=directors1.groupby(\"Director_1\", as_index=True)[\"success\"].agg(['count', 'sum'])  # index is director name\n",
    "d1.rename(columns={'count':'count1', 'sum':'sum1'})\n",
    "d2=directors2.groupby(\"Director_2\", as_index=True)[\"success\"].agg(['count', 'sum'])  # index is director name\n",
    "d2.rename(columns={'count':'count2', 'sum':'sum2'})\n",
    "print(f'\\n directors1: count unique: {len(d1)}, index: {d1.index}, head: {d1.head()}')\n",
    "print(f'\\n directors2: count_unique: {len(d2)}, index: {d2.index}, head: {d2.head()}')\n",
    "\n",
    "# then concatenate and combine matching director names\n",
    "# join counts by index (director name), this will creates nulls from d2\n",
    "# calculate total movies count and success rate for each director\n",
    "# output d1 has Director as index, and columns movie_cnt  success_cnt  win_rate\n",
    "print(d1.index, d2.index)\n",
    "d1 = d1.join(d2, how=\"outer\", rsuffix=\"2\")\n",
    "d1 = d1.replace(np.nan,0)\n",
    "d1[\"movie_cnt\"] = d1[\"count\"] + d1[\"count2\"]\n",
    "d1[\"success_cnt\"] = d1[\"sum\"] + d1[\"sum2\"] \n",
    "d1[\"win_rate\"] = d1[\"success_cnt\"] / d1[\"movie_cnt\"]\n",
    "d1.drop([\"count\", \"sum\", \"count2\", \"sum2\"], axis=1, inplace=True)\n",
    "d1.index.name = \"Director\"\n",
    "print(f'\\n {d1.index}')\n",
    "print(f'\\n {d1.head()}')\n",
    "print(f'\\n {len(d1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'g_Action_IM', 'g_Adult', 'g_Adventure_IM',\n",
       "       'g_Animation_IM', 'g_Biography', 'g_Comedy_IM', 'g_Crime_IM',\n",
       "       'g_Documentary_IM', 'g_Drama_IM', 'g_Family_IM', 'g_Fantasy_IM',\n",
       "       'g_History_IM', 'g_Horror_IM', 'g_Music_IM', 'g_Musical',\n",
       "       'g_Mystery_IM', 'g_Romance_IM', 'g_Thriller_IM', 'g_War_IM',\n",
       "       'g_Western_IM', 'release_year_IM', 'success', 'Director_1',\n",
       "       'Director_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_cnt', 'success_cnt', 'win_rate'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Director'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Director_1', 'Director_2', 'movie_cnt', 'success_cnt', 'win_rate',\n",
      "       'movie_cnt_2', 'success_cnt_2', 'win_rate_2'],\n",
      "      dtype='object')\n",
      "Index(['Director_1', 'Director_2', 'movie_cnt', 'success_cnt', 'win_rate',\n",
      "       'movie_cnt_2', 'success_cnt_2', 'win_rate_2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Calculate director ratings\n",
    "# there's got to be a better way to do this\n",
    "# Get only Director_1 and Director_2 from df, then merge each column with d1 on Director\n",
    "# the result is Director_1, movie_cnt, win_rate, Director_2, movie_cnt_2, win_rate_2, index is still from the original df\n",
    "\n",
    "df_subset = df[[\"Director_1\", \"Director_2\"]].copy()\n",
    "df_subset.sort_values(by=\"Director_1\")\n",
    "d1.sort_values(by=\"Director\")\n",
    "df_subset = df_subset.merge(d1, how=\"left\", left_on = \"Director_1\", right_on = \"Director\")\n",
    "df_subset.sort_values(by=\"Director_2\")\n",
    "df_subset = df_subset.merge(d1, how=\"left\", left_on = \"Director_2\", right_on = \"Director\", suffixes=(None, \"_2\"))\n",
    "print(df_subset.columns)\n",
    "\n",
    "# calculate the max movie_cnt and max win_rate across Director_1, Director_2 for each movie.\n",
    "# prepare data for calculations\n",
    "df_subset['movie_cnt_2'].fillna(0, inplace=True)\n",
    "df_subset['success_cnt_2'].fillna(0, inplace=True)\n",
    "df_subset['win_rate_2'].fillna(0, inplace=True)\n",
    "print(df_subset.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Director_1', 'Director_2', 'movie_cnt', 'success_cnt', 'win_rate',\n",
      "       'movie_cnt_2', 'success_cnt_2', 'win_rate_2'],\n",
      "      dtype='object')\n",
      "    director_score_cnt  director_score_rate\n",
      "0                  1.0             0.000000\n",
      "1                  1.0             0.000000\n",
      "2                  1.0             1.000000\n",
      "3                  1.0             1.000000\n",
      "4                  2.0             1.000000\n",
      "5                  1.0             0.000000\n",
      "6                  2.0             1.000000\n",
      "7                  1.0             1.000000\n",
      "9                  4.0             0.000000\n",
      "10                11.0             0.545455\n",
      "11                11.0             0.272727\n",
      "12                 3.0             0.333333\n",
      "14                 9.0             0.666667\n",
      "15                 4.0             1.000000\n",
      "16                 6.0             0.500000\n",
      "17                 4.0             0.000000\n",
      "18                 4.0             1.000000\n",
      "19                 1.0             0.000000\n",
      "20                 1.0             1.000000\n",
      "23                 1.0             0.000000\n",
      "Index(['duration', 'g_Action_IM', 'g_Adult', 'g_Adventure_IM',\n",
      "       'g_Animation_IM', 'g_Biography', 'g_Comedy_IM', 'g_Crime_IM',\n",
      "       'g_Documentary_IM', 'g_Drama_IM', 'g_Family_IM', 'g_Fantasy_IM',\n",
      "       'g_History_IM', 'g_Horror_IM', 'g_Music_IM', 'g_Musical',\n",
      "       'g_Mystery_IM', 'g_Romance_IM', 'g_Thriller_IM', 'g_War_IM',\n",
      "       'g_Western_IM', 'release_year_IM', 'success', 'Director_1',\n",
      "       'Director_2', 'director_score_cnt', 'director_score_rate'],\n",
      "      dtype='object')\n",
      "56531\n"
     ]
    }
   ],
   "source": [
    "# For each movie determine the highest director dating\n",
    "# Where there are 2 directors, take the max win_rate and the max movies_cnt for the movie score   \n",
    "# columns are in this order:  0:Director_1  1:Director_2  2:movie_cnt  3:success_cnt 4:win_rate  5:movie_cnt_2  \n",
    "# 6:success_cnt_2  7:win_rate_2  \n",
    "# columns in director_ratings: 0:director_score_cnt 1:director_score_rate\n",
    "\n",
    "directors_ratings = pd.DataFrame(index=df.index.copy())  # initialize df to hold directors ratings, index=original\n",
    "       \n",
    "for index, row  in df_subset.iterrows():\n",
    "    if row[5] is not None and row[5] > row[2]:\n",
    "        directors_ratings.loc[index, 0] = row[5]\n",
    "    else:\n",
    "        directors_ratings.loc[index, 0] = row[2]\n",
    "    if row[7] is not None and row[7] > row[4]:\n",
    "        directors_ratings.loc[index, 1] = row[7]\n",
    "    else:\n",
    "        directors_ratings.loc[index, 1] = row[4]\n",
    "\n",
    "print(df_subset.columns)\n",
    "directors_ratings.columns = (\"director_score_cnt\", \"director_score_rate\")\n",
    "print(directors_ratings.head(20))\n",
    "\n",
    "# add director ratings to df on original index\n",
    "df = pd.concat([df, directors_ratings], axis=1, ignore_index=False, join=\"inner\")\n",
    "print(df.columns)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'g_Action_IM', 'g_Adult', 'g_Adventure_IM',\n",
      "       'g_Animation_IM', 'g_Biography', 'g_Comedy_IM', 'g_Crime_IM',\n",
      "       'g_Documentary_IM', 'g_Drama_IM', 'g_Family_IM', 'g_Fantasy_IM',\n",
      "       'g_History_IM', 'g_Horror_IM', 'g_Music_IM', 'g_Musical',\n",
      "       'g_Mystery_IM', 'g_Romance_IM', 'g_Thriller_IM', 'g_War_IM',\n",
      "       'g_Western_IM', 'release_year_IM', 'success', 'Director_1',\n",
      "       'Director_2', 'director_score_cnt', 'director_score_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.drop([\"Director_1\", \"Director_2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where director data is missing\n",
    "df.dropna(axis=1, how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration            0\n",
       "g_Action_IM         0\n",
       "g_Adult             0\n",
       "g_Adventure_IM      0\n",
       "g_Animation_IM      0\n",
       "g_Biography         0\n",
       "g_Comedy_IM         0\n",
       "g_Crime_IM          0\n",
       "g_Documentary_IM    0\n",
       "g_Drama_IM          0\n",
       "g_Family_IM         0\n",
       "g_Fantasy_IM        0\n",
       "g_History_IM        0\n",
       "g_Horror_IM         0\n",
       "g_Music_IM          0\n",
       "g_Musical           0\n",
       "g_Mystery_IM        0\n",
       "g_Romance_IM        0\n",
       "g_Thriller_IM       0\n",
       "g_War_IM            0\n",
       "g_Western_IM        0\n",
       "release_year_IM     0\n",
       "success             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     9,\n",
       "               10,\n",
       "            ...\n",
       "            70510, 70511, 70512, 70513, 70514, 70516, 70517, 70520, 70523,\n",
       "            70525],\n",
       "           dtype='int64', length=56531)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code - calculates only number of movies\n",
    "\n",
    "# pd.set_option(\"max_rows\", None)\n",
    "# # extract info from director feature\n",
    "# # there are 52,754 movies with 1 director, and 3,777 movies with 2 directors\n",
    "# # there are 26,593 unique values of \"director\" (counting a pair of directors as a single value)\n",
    "\n",
    "# # hypothesis: more movies associated with a director indicates the director is considered more worthy of investment, \n",
    "# # so considered by investors to be more successful?\n",
    "# # 58% of directors have 1 movie\n",
    "# # 17% of directors have 2 movies\n",
    "# #  7% of directors have 3 movies\n",
    "\n",
    "# # hypothesis: can calculate success ratio for each director and use as a feature in the model\n",
    "\n",
    "# # Issue = names with a single quote are inside double quotes\n",
    "# # in merged file looks like: Joe D'Amato\"\"]\"\n",
    "# # see how this is handled in database\n",
    "# # may need to modify the search based on the contents of the database\n",
    "\n",
    "# directors = df[\"director_list\"] # directors in a string\n",
    "# director_list = directors.str.split(',')   # splits string into words outputs to a list\n",
    "# director_cds = directors.str.split(',', expand=True)   # outputs split words to separate columns\n",
    "# director_cds.columns=[\"A\", \"B\"]\n",
    "# directors1 = director_cds[\"A\"].str.replace('[', '')\n",
    "# directors1 = directors1.str.replace(']', '')\n",
    "# directors1 = directors1.str.replace(\"'\", \"\")\n",
    "# directors2 = director_cds[\"B\"].str.replace(']', '')\n",
    "# directors2 = directors2.str.replace(\"'\", \"\")\n",
    "# directors1 = directors1.str.strip()\n",
    "# directors2 = directors2.str.strip().dropna()\n",
    "\n",
    "# directors1_counts = directors1.value_counts()  # index is now director name\n",
    "# directors2_counts = directors2.value_counts()\n",
    "\n",
    "# # print(f'\\n directors1: count unique: {len(directors1_counts)}, head: {directors1_counts.head()}')\n",
    "# # print(f'\\n directors2: count_unique: {len(directors2_counts)}, head: {directors2_counts.head()}')\n",
    "\n",
    "# director_counts = pd.DataFrame()\n",
    "# director_counts[\"A\"]=directors1_counts  # A is now numpy.int64\n",
    "# director_counts[\"B\"]=directors2_counts  # B is now numpy.float64\n",
    "# director_counts[\"B\"] = director_counts[\"B\"].replace(np.nan,0)\n",
    "# director_counts[\"total_count\"] = director_counts[\"A\"] + director_counts[\"B\"]\n",
    "\n",
    "# print(director_counts.describe())\n",
    "# print(director_counts.value_counts())\n",
    "\n",
    "# # Calculate personal success rate for each director"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'S':  # create encoded and scaled dataset\n",
    "    # Encode categorical variables\n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df =pd.DataFrame(enc.fit_transform(df[cat_vars]))\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns =enc.get_feature_names(cat_vars)\n",
    "    # Merge one-hot encoded features and drop the originals\n",
    "    df =df.merge(encode_df,left_index=True,right_index=True)\n",
    "    df.drop(cat_vars,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y =df[\"success\"].values\n",
    "X =df.drop([\"success\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,stratify=y,random_state=67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'S':  # create encoded and scaled dataset\n",
    "    X_scaler = StandardScaler()\n",
    "    # Fit the scaler\n",
    "    X_scaler.fit(X_train)\n",
    "    # Scale the data\n",
    "    X_train =X_scaler.transform(X_train)\n",
    "    X_test =X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic regression model accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"LR\":\n",
    "    log_classifier =LogisticRegression(solver=\"lbfgs\",max_iter=200)\n",
    "\n",
    "    # Train the model\n",
    "    log_classifier.fit(X_train,y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred =log_classifier.predict(X_test)\n",
    "    print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"SV\":\n",
    "    # Create the SVM model\n",
    "    svm =SVC(kernel='linear')\n",
    "    print('created svm')\n",
    "    # Train the model\n",
    "    svm.fit(X_train,y_train)\n",
    "    print('fit svm')\n",
    "    # Evaluate the model\n",
    "    y_pred =svm.predict(X_test_scaled)\n",
    "    print('predicted svm')\n",
    "    print(f\" SVM model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"NN\":\n",
    "    # Create the Keras Sequential model\n",
    "    # use validation_split argument to set the proportion of the dataset to reserve for validation\n",
    "    number_input_features =len(X_train[0])\n",
    "    hidden_nodes_layer1 = 5\n",
    "    hidden_nodes_layer2 = 3\n",
    "    nn =tf.keras.models.Sequential()\n",
    "    # layers\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,activation=\"tanh\",input_dim=number_input_features))\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,activation=\"tanh\"))\n",
    "\n",
    "    # Add the output layer that uses a probability activation function\n",
    "    nn.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
    "    \n",
    "    # Check the structure of the Sequential model\n",
    "    nn.summary()\n",
    "\n",
    "    # Compile the Sequential model together and customize metrics\n",
    "    nn.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    fit_model =nn.fit(X_train,y_train,validation_split=.3, epochs=15)\n",
    "\n",
    "    # Evaluate the model using the test data\n",
    "    model_loss,model_accuracy =nn.evaluate(X_test,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "    \n",
    "    # Create learning curve for both train and validation datasets to evaluate under- and over-fitting\n",
    "\n",
    "    history_dict=fit_model.history\n",
    "\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    accuracy = history_dict['accuracy']\n",
    "    val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    #\n",
    "    # Plot the model accuracy vs Epochs\n",
    "    #\n",
    "    ax[0].plot(epochs, accuracy, 'b', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_accuracy, 'g', label='Validation accuracy')\n",
    "    ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
    "    ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "    ax[0].set_ylabel('Accuracy', fontsize=16)\n",
    "    ax[0].legend()\n",
    "    #\n",
    "    # Plot the loss vs Epochs\n",
    "    #\n",
    "    ax[1].plot(epochs, loss_values, 'b', label='Training loss')\n",
    "    ax[1].plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "    ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
    "    ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "    ax[1].set_ylabel('Loss', fontsize=16)\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37nbext",
   "language": "python",
   "name": "py37nbext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
